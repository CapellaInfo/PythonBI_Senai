{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Análise de Imagens**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Análise de imagens utilizando as bibliotecas OpenCv e Pillow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# Carregar uma imagem usando OpenCV\n",
    "image_opencv = cv2.imread('images/imagem.png') # Transforma a imagem em uma matriz de pixels\n",
    "# print(image_opencv)\n",
    "\n",
    "# Abrir uma imagem usando PIL\n",
    "image_pil = Image.open('images/imagem.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redimensionar a imagem usando OpenCV\n",
    "imagem_redimensionada_opencv = cv2.resize(image_opencv, (500, 500))\n",
    "plt.imshow(imagem_redimensionada_opencv)\n",
    "\n",
    "# Rotacionar a imagem usando PIL\n",
    "imagem_rotacionada_pil = image_pil.rotate(45)\n",
    "plt.imshow(imagem_rotacionada_pil)\n",
    "\n",
    "# Recortar a imagem usando OpenCV\n",
    "imagem_recortada_opencv = image_opencv[100:1300, 300:600]\n",
    "plt.imshow(imagem_recortada_opencv)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter a imagem para outro formato usando OpenCV\n",
    "cv2.imwrite('images/imagem_conversao.jpg', image_opencv)\n",
    "\n",
    "# Converter a imagem para outro formato usando PIL\n",
    "image_pil.save('images/imagem_conversao.jpg', format='PNG')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Aplicação de Filtro de Suavização com OpenCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar a imagem\n",
    "imagem = cv2.imread('images/imagem.jpg')\n",
    "# Aplicar filtro de suavização (média)\n",
    "\n",
    "imagem_suavizada = cv2.blur(imagem, (5, 5))  # kernel de 5x5\n",
    "plt.imshow(imagem_suavizada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar a imagem\n",
    "imagem = cv2.imread('images/imagem.jpg')\n",
    "\n",
    "# Aplicar filtro de mediana para remover ruído\n",
    "imagem_sem_ruido = cv2.medianBlur(imagem, 5)  # kernel de 5x5\n",
    "plt.imshow(imagem_sem_ruido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar a imagem em escala de cinza?\n",
    "imagem = cv2.imread('images/imagem.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Equalizar o histograma da imagem\n",
    "imagem_equalizada = cv2.equalizeHist(imagem)\n",
    "plt.imshow(imagem_equalizada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar a imagem em escala de cinza\n",
    "imagem = cv2.imread('images/imagem.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Aplicar limiarização\n",
    "imagem_segmentada = cv2.threshold(imagem, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Mostrar a imagem segmentada\n",
    "plt.imshow(imagem_segmentada, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Segmentação por Limiarização')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar a imagem\n",
    "imagem = cv2.imread('images/imagem.jpg')\n",
    "imagem_gray = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Aplicar detecção de contornos\n",
    "contornos, _ = cv2.findContours(imagem_gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Desenhar os contornos na imagem original\n",
    "cv2.drawContours(imagem, contornos, -1, (0, 255, 0), 2)\n",
    "\n",
    "# Mostrar a imagem com contornos\n",
    "plt.imshow(cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.title('Segmentação por Contornos')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Segmentação baseada em Aprendizado de Máquina**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo usando biblioteca scikit-learn e K-means\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Converter imagem para um vetor 1D\n",
    "imagem_reshaped = imagem.reshape((-1, 3))\n",
    "\n",
    "# Aplicar K-means para segmentação\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(imagem_reshaped)\n",
    "clusters = kmeans.predict(imagem_reshaped)\n",
    "\n",
    "# Remontar a imagem segmentada\n",
    "imagem_segmentada = clusters.reshape(imagem.shape[:2])\n",
    "\n",
    "# Mostrar a imagem segmentada\n",
    "plt.imshow(imagem_segmentada, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Segmentação por Aprendizado de Máquina (K-means)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Converter imagem para um vetor 1D\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m imagem_reshaped \u001b[38;5;241m=\u001b[39m \u001b[43mimagem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Aplicar K-means para segmentação\u001b[39;00m\n\u001b[0;32m      5\u001b[0m kmeans \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "# Converter imagem para um vetor 1D\n",
    "imagem_reshaped = imagem.reshape((-1, 3))\n",
    "\n",
    "# Aplicar K-means para segmentação\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(imagem_reshaped)\n",
    "clusters = kmeans.predict(imagem_reshaped)\n",
    "\n",
    "# Remontar a imagem segmentada\n",
    "imagem_segmentada = clusters.reshape(imagem.shape[:2])\n",
    "\n",
    "# Encontrar contornos na imagem segmentada\n",
    "contornos, _ = cv2.findContours(imagem_segmentada.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Criar uma cópia da imagem original para desenhar os contornos\n",
    "imagem_com_contornos = imagem.copy()\n",
    "\n",
    "# Desenhar os contornos na imagem original\n",
    "cv2.drawContours(imagem_com_contornos, contornos, -1, (0, 255, 0), 2)\n",
    "\n",
    "# Mostrar a imagem com contornos\n",
    "plt.imshow(cv2.cvtColor(imagem_com_contornos, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.title('Segmentação por Aprendizado de Máquina (K-means) com Contornos')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Carregar a imagem\u001b[39;00m\n\u001b[0;32m      2\u001b[0m imagem \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagem.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m imagem \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimagem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Converter para o formato RGB\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Redimensionar a imagem para facilitar o processamento\u001b[39;00m\n\u001b[0;32m      6\u001b[0m altura, largura \u001b[38;5;241m=\u001b[39m imagem\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "# Carregar a imagem\n",
    "imagem = cv2.imread('imagem.jpg')\n",
    "imagem = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)  # Converter para o formato RGB\n",
    "\n",
    "# Redimensionar a imagem para facilitar o processamento\n",
    "altura, largura = imagem.shape[:2]\n",
    "imagem_redimensionada = cv2.resize(imagem, (largura // 2, altura // 2))\n",
    "\n",
    "# Preparar os dados para o K-means\n",
    "dados = imagem_redimensionada.reshape((-1, 3))\n",
    "\n",
    "# Aplicar K-means para segmentação\n",
    "kmeans = KMeans(n_clusters=4)  # Definir o número de clusters\n",
    "kmeans.fit(dados)\n",
    "segmentos = kmeans.labels_\n",
    "centroides = kmeans.cluster_centers_\n",
    "\n",
    "# Remontar a imagem segmentada\n",
    "imagem_segmentada = np.zeros_like(dados)\n",
    "for i, cor in enumerate(centroides):\n",
    "    imagem_segmentada[segmentos == i] = cor\n",
    "imagem_segmentada = imagem_segmentada.reshape(imagem_redimensionada.shape)\n",
    "\n",
    "# Mostrar a imagem original e a imagem segmentada\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(imagem_redimensionada)\n",
    "plt.title('Imagem Original')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(imagem_segmentada)\n",
    "plt.title('Imagem Segmentada')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m imagem \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mformas.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Converter a imagem para escala de cinza\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m imagem_gray \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimagem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2GRAY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Aplicar uma limiarização para segmentar as formas\u001b[39;00m\n\u001b[0;32m      8\u001b[0m _, imagem_binaria \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mthreshold(imagem_gray, \u001b[38;5;241m240\u001b[39m, \u001b[38;5;241m255\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mTHRESH_BINARY)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "# Carregar a imagem\n",
    "imagem = cv2.imread('formas.jpg')\n",
    "\n",
    "# Converter a imagem para escala de cinza\n",
    "imagem_gray = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Aplicar uma limiarização para segmentar as formas\n",
    "_, imagem_binaria = cv2.threshold(imagem_gray, 240, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Encontrar contornos na imagem binária\n",
    "contornos, _ = cv2.findContours(imagem_binaria, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Criar uma cópia da imagem original para desenhar os contornos\n",
    "imagem_com_contornos = imagem.copy()\n",
    "\n",
    "# Desenhar os contornos na imagem original\n",
    "cv2.drawContours(imagem_com_contornos, contornos, -1, (0, 255, 0), 2)\n",
    "\n",
    "# Mostrar a imagem com os contornos das formas\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Imagem Original')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(cv2.cvtColor(imagem_com_contornos, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Contornos das Formas')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m classificador_faces \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mCascadeClassifier(cv2\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mhaarcascades \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhaarcascade_frontalface_default.xml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Converter a imagem para escala de cinza (necessário para detecção de objetos)\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m imagem_gray \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimagem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2GRAY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Detectar rostos na imagem\u001b[39;00m\n\u001b[0;32m     14\u001b[0m faces \u001b[38;5;241m=\u001b[39m classificador_faces\u001b[38;5;241m.\u001b[39mdetectMultiScale(imagem_gray, scaleFactor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.1\u001b[39m, minNeighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, minSize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m30\u001b[39m))\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Carregar a imagem\n",
    "imagem = cv2.imread('images/image.png')\n",
    "\n",
    "# Carregar o classificador de detecção de faces pré-treinado\n",
    "classificador_faces = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Converter a imagem para escala de cinza (necessário para detecção de objetos)\n",
    "imagem_gray = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detectar rostos na imagem\n",
    "faces = classificador_faces.detectMultiScale(imagem_gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "# Desenhar retângulos ao redor dos rostos detectados\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(imagem, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "# Exibir a imagem com os rostos detectados\n",
    "plt.imshow(cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Detecção de Rostos')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
